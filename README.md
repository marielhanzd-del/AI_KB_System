AI Knowledge Base System

This project is a Retrieval-Augmented Generation (RAG) system built in under 24 hours using FastAPI, FAISS, SentenceTransformers, and Google Gemini.
It allows users to upload documents, embed their contents into a vector database, and query them with context-grounded answers generated by Gemini.

üèóÔ∏è Design Decisions

FastAPI for backend

Chosen for its speed, async support, and automatic interactive docs (/docs).

Lightweight enough to quickly prototype within 24 hours.

FAISS as in-memory vector store

Provides efficient similarity search.

Using IndexFlatL2 for simplicity and speed.

Kept in-memory only to avoid disk persistence complexity.

SentenceTransformers (all-MiniLM-L6-v2)

Embedding model chosen for balance between speed and semantic quality.

384-dimension embeddings allow smaller memory footprint while remaining effective.

Chunking & Storage

Text extracted from PDFs and stored as small chunks in DOC_STORE.

Each chunk is linked to its FAISS embedding for retrieval.

Gemini Integration

Gemini takes the retrieved chunks + user question to generate context-aware answers.

This ensures responses are not generic but grounded in uploaded docs.

‚öñÔ∏è Trade-offs (24h Constraint)

No persistence: FAISS index and documents are reset when the server restarts.

Basic chunking: Used simple paragraph-based chunking instead of advanced sliding-window overlap.

Error handling: Minimal ‚Äì limited retries for PDF parsing and Gemini API errors.

Testing scope: Focused on core upload/query flow rather than unit testing edge cases.

Security: API key is passed via environment variable but lacks full auth/roles support.

Scalability: Designed for demo-level scale (few documents, single user), not production load.

These trade-offs allowed delivering a working end-to-end RAG pipeline within 24 hours.

‚öôÔ∏è How to Run
1. Clone repo & create environment
git clone https://github.com/your-username/ai-kb-system.git
cd ai-kb-system
python3 -m venv venv
source venv/bin/activate   # (Windows: venv\Scripts\activate)

2. Install dependencies
pip install -r requirements.txt

3. Set environment variable
export GOOGLE_API_KEY="your-gemini-api-key"

4. Start server
uvicorn app.main:app --reload


The server runs at: http://127.0.0.1:8000

Interactive Swagger docs: http://127.0.0.1:8000/docs

üß™ How to Test
Upload a document
curl -X POST "http://127.0.0.1:8000/upload" \
  -F "file=@resume.pdf"

Query the knowledge base
curl -X POST "http://127.0.0.1:8000/query" \
  -F "question=Who is Kinza?"

Example Response
{
  "question": "Who is Kinza?",
  "answer": "Kinza Yousaf is an AI Software Engineer with 5+ years of experience...",
  "matched_chunks": [
    "kinzayousaf.001@gmail.com linkedin.com/in/kinza-y/ ...",
    "AI Engineer, Hoja AI Built an LLM agent ...",
    "Machine Learning Engineer, cPacket ..."
  ]
}

üöÄ Future Improvements

Add FAISS persistence (save/load index).

Better chunking (sliding windows, semantic splits).

Frontend for upload + query.

API authentication & rate limiting.

Dockerize for easier deployment.